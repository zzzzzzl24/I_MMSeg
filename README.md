# I_MMSeg
This repo holds code for [Incorporating Modality-Specific Intensity Prior as Text Prompt for Multimodal Myocardial Pathology Segmentation]

## ðŸ“˜ Abstract Figure
![Abstract Figure](./abstract.png)

## ðŸ“° News
- [11/22/2025] I_MMSeg is an intensity-guided multimodal CMR segmentation framework for myocardial pathology segmentation. The method introduces modality-specific intensity priors generated by multimodal large language models (e.g., GPT-4o), and encodes them using a CLIP-based prior encoder. Two tailored modulesâ€”an intensity-prior-guided cross-modal feature enhancement module and a class feature modulation moduleâ€”integrate these priors into the segmentation pipeline, improving cross-modal feature discrimination and boosting overall segmentation accuracy.

This repository hosts a review-version implementation of I_MMSeg.
It is provided solely for peer-review and reproducibility checking, and is not the final public release.

## Usage

### 1. Download Pre-trained Models and Dataset

Please download the following resources:

- **ViT pre-trained weights**
- **I_MMSeg model weights**
- **MyoPS380 dataset (Raw data + Processed data)**

ðŸ‘‰ Download link: [Google Drive](https://drive.google.com/drive/folders/1s8MCmZDA5kslwicDBFamX3hXiY72EkzX?usp=drive_link)

The Download link contains three components: ViT_checkpoint, I_MMSeg_checkpoint, and MyoPS380_dataset(Issued upon approval).
Please organize them as follows:

Move the ViT pre-trained weight files inside ViT_checkpoint to:
```bash
../model/vit_checkpoint/imagenet21k/
```

Move the I_MMSeg_MyoPS380 model weight files into:
```bash
../weights/TU_Myops128/TU_pretrain_R50-ViT-B_16_skip3_epo300_bs24_lr0.001_128/
```

For the MyoPS380_dataset folder, please proceed to Section 5. Dataset Description to obtain the download link:

The Raw_data/ directory contains the original data organized into bSSFP, LGE, T2w, and label.

The Processed_data/ directory contains preprocessed data generated by preprocess_data.py and is used for model training and inference.

**Please place the dataset directories according to the root_path settings specified in train.py and test.py.**

---

### 2. Place the downloaded files into the correct directories

The project uses the following directory structure:
```bash
I_MMSeg/
â”œâ”€â”€ model/
â”‚   â””â”€â”€ vit_checkpoint/
â”‚        â””â”€â”€ imagenet21k/              
â”‚             # place ViT .npz weights here
â”‚
â”œâ”€â”€ weights/
â”‚   â””â”€â”€ TU_Myops128/
â”‚        â””â”€â”€ TU_pretrain_R50-ViT-B_16_skip3_epo300_bs24_lr0.001_128/
â”‚             # place I-MMSeg model weights here
â”‚
â”œâ”€â”€ MyoPS380_dataset/
â”‚   â”œâ”€â”€ Raw_data/ 
â”‚   â”‚   â”œâ”€â”€ bSSFP/        # raw bssfp, t2w, lge, label
â”‚   â”‚   â”‚     â”œâ”€â”€ case0001.nii.gz
â”‚   â”‚   â”‚     â”œâ”€â”€ ...
â”‚   â”‚   â”‚     â””â”€â”€ case0380.nii.gz
â”‚   â”‚   â”œâ”€â”€ LGE/
â”‚   â”‚   â”œâ”€â”€ T2w/
â”‚   â”‚   â””â”€â”€ label/
â”‚   â”‚         â”œâ”€â”€ case0001_gt.nii.gz
â”‚   â”‚         â”œâ”€â”€ ...
â”‚   â”‚         â””â”€â”€ case0380_gt.nii.gz   
â”‚   â”‚                              
â”‚   â””â”€â”€ Processed_data/   # preprocessed data for training/testing
â”‚       â”œâ”€â”€ bSSFP/
â”‚       â”‚     â”œâ”€â”€ train_npz
â”‚       â”‚     â”‚    â”œâ”€â”€ case0002_slice000.npz
â”‚       â”‚     â”‚    â”œâ”€â”€ case0002_slice001.npz
â”‚       â”‚     â”‚    â”œâ”€â”€ ...          
â”‚       â”‚     â”‚    â””â”€â”€ case0380_slice003.npz   
â”‚       â”‚     â””â”€â”€ test_vol_h5
â”‚       â”‚          â”œâ”€â”€ case0001.npy.h5
â”‚       â”‚          â”œâ”€â”€ case0006.npy.h5
â”‚       â”‚          â”œâ”€â”€ ...          
â”‚       â”‚          â””â”€â”€ case0376.npy.h5  
â”‚       â”œâ”€â”€ LGE/
â”‚       â””â”€â”€ T2w/
â”œâ”€â”€ preprocess_data.py                 # preprocessing script
â”œâ”€â”€ train.py                           # training script
â”œâ”€â”€ test.py                            # inference script
â”œâ”€â”€ environment.yaml                   # Reproducible conda environment definition
â””â”€â”€ README.md
```

### 3. Environment

This project is implemented with **Python 3.8**, **CUDA 11.8**, and **PyTorch 2.2**.  
Please prepare a conda environment and install all dependencies via:

```bash
conda env create -f environment.yaml
conda activate I_MMSeg
```

### 4. Train/Test

- Run the train script on MyoPS380 dataset. The batch size can be reduced to 12 or 6 to save memory (please also decrease the base_lr linearly), and both can reach similar performance.

```bash
CUDA_VISIBLE_DEVICES= "0,1" python train.py --dataset Myops --vit_name R50-ViT-B_16
```

- Run the test script on MyoPS380 dataset.

```bash
python test.py --dataset Myops --vit_name R50-ViT-B_16
```

### 5. Dataset Description

The **MyoPS380 dataset** is currently undergoing peer review as part of an accompanying publication.  
Pending successful completion of the final compliance check, it is expected to be publicly released **before January 2026**.

Assessing myocardial viability is crucial for the diagnosis and clinical management of patients with myocardial infarction (MI).  
Cardiac MRI (CMR) plays a central role in this process by providing detailed anatomical, functional, and tissue-characterization information.  
Three commonly used CMR sequences offer complementary insights:

- **LGE (Late Gadolinium Enhancement)** â€” visualizes myocardial infarction and fibrosis;  
- **T2-weighted** â€” highlights acute injury and edema regions;  
- **bSSFP** â€” captures cardiac motion and provides clear anatomical boundaries.

Integrating these sequences yields comprehensive structural and pathological information, supporting the classification of myocardial tissue into **normal**, **Scar**, and **edema** regions.  
However, manual annotation is often time-consuming, labor-intensive, and subject to inter- and intra-observer variability.  
Therefore, **automated multimodal myocardial pathology segmentation** is highly desirable in clinical applications.

To facilitate research in this direction, the **MyoPS380 dataset** provides multimodal CMR data from **380 patients**, including bSSFP, T2W, and LGE sequences along with corresponding pixel-level annotations. This dataset serves as a high-quality benchmark for developing novel algorithms that exploit complementary information across modalities to perform reliable myocardial pathology classification and segmentation. It is intended to support the creation of robust, clinically applicable intelligent diagnostic systems.

You can download the dataset release agreement from ðŸ‘‰ [here](./MyoPS380_Dataset_Release_Agreement.docx).

Please ensure that a permanent or long-term responsible person (e.g., professor) completes the form with a **handwritten signature**.  
After signing, send the scanned electronic version to:**donggenf@whu.edu.cn**, **Subject:** *MyoPS380 Dataset Release Agreement*.
Please send the email from an **institutional email address** (e.g., xxx@xxx.edu.xx). Requests sent from free email providers (Outlook, QQ, Hotmail, etc.) will be politely declined.

After verifying your information, we will send you the dataset download link. We usually reply within a week. If you do not receive a responseâ€”possibly due to delivery issuesâ€”please modify the email content or title and try resending.

## Reference
* [Google ViT](https://github.com/google-research/vision_transformer)
* [ViT-pytorch](https://github.com/jeonsworld/ViT-pytorch)
* [TransUNet](https://github.com/Beckschen/TransUNet/tree/main)

<!-- ## Citations


```bibtex
@article{chen2021transunet,
  title={TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation},
  author={Chen, Jieneng and Lu, Yongyi and Yu, Qihang and Luo, Xiangde and Adeli, Ehsan and Wang, Yan and Lu, Le and Yuille, Alan L., and Zhou, Yuyin},
  journal={arXiv preprint arXiv:2102.04306},
  year={2021}
}
``` -->
