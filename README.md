# I_MMSeg
This repo holds code for [Incorporating Modality-Specific Intensity Prior as Text Prompt for Multimodal Myocardial Pathology Segmentation].

## ðŸ“˜ Abstract Figure
![Abstract Figure](./abstract.png)

## ðŸ“° News
- [11/22/2025] I_MMSeg is an intensity-guided multimodal CMR segmentation framework for myocardial pathology segmentation. The method introduces modality-specific intensity priors generated by multimodal large language models (e.g., GPT-4o), and encodes them using a CLIP-based prior encoder. Two tailored modulesâ€”an intensity-prior-guided cross-modal feature enhancement module and a class feature modulation moduleâ€”integrate these priors into the segmentation pipeline, improving cross-modal feature discrimination and boosting overall segmentation accuracy.

This repository hosts a review-version implementation of I_MMSeg.
It is provided solely for peer-review and reproducibility checking, and is not the final public release.

## Usage

### 1. Download Environment Package, Pre-trained Weights, and Dataset

Please download the following resources:

- **I_MMSeg environment configuration**
- **ViT pre-trained weights**
- **I_MMSeg model weights**
- **MyoPS380 dataset (Raw data + Processed data)**

ðŸ‘‰ Download link: [Google Drive](https://drive.google.com/drive/folders/1s8MCmZDA5kslwicDBFamX3hXiY72EkzX?usp=drive_link)

The Download link contains three components: ViT_checkpoint, I_MMSeg_checkpoint, and MyoPS380_dataset(Issued upon approval).
Please organize them as follows:

Environment:This project is implemented with **Python 3.8**, **CUDA 11.8**, and **PyTorch 2.2**.  
Please download the environment files and extract the environment package:

```bash
mkdir -p ./miniconda3/envs/I_MMSeg
tar -xzf I_MMSeg_env.tar.gz -C ./miniconda3/envs/I_MMSeg
cd ./miniconda3/envs/I_MMSeg
./bin/conda-unpack
source ./miniconda3/envs/I_MMSeg/bin/activate
```

Move the ViT pre-trained weight files inside ViT_checkpoint to:
```bash
../model/vit_checkpoint/imagenet21k/
```

Move the I_MMSeg_MyoPS380 model weight files into:
```bash
../weights/TU_Myops128/TU_pretrain_R50-ViT-B_16_skip3_epo300_bs24_lr0.001_128/
```

For the MyoPS380_dataset folder, please proceed to Section 5. Dataset Description to obtain the download link:

The Raw_data/ directory contains the original data organized into bSSFP, LGE, T2w, and label.

The Processed_data/ directory contains preprocessed data generated by preprocess_data.py and is used for model training and inference.

**Please place the dataset directories according to the root_path settings specified in train.py and test.py.**

---

### 2. Place the downloaded files into the correct directories

The project uses the following directory structure:
```bash
I_MMSeg/
â”œâ”€â”€ model/
â”‚   â””â”€â”€ vit_checkpoint/
â”‚        â””â”€â”€ imagenet21k/              
â”‚             # place ViT .npz weights here
â”‚
â”œâ”€â”€ weights/
â”‚   â””â”€â”€ TU_Myops128/
â”‚        â””â”€â”€ TU_pretrain_R50-ViT-B_16_skip3_epo300_bs24_lr0.001_128/
â”‚             # place I-MMSeg model weights here
â”‚
â”œâ”€â”€ MyoPS380_dataset/
â”‚   â”œâ”€â”€ Raw_data/ 
â”‚   â”‚   â”œâ”€â”€ bSSFP/        # raw bssfp, t2w, lge, label
â”‚   â”‚   â”‚     â”œâ”€â”€ case0001.nii.gz
â”‚   â”‚   â”‚     â”œâ”€â”€ ...
â”‚   â”‚   â”‚     â””â”€â”€ case0380.nii.gz
â”‚   â”‚   â”œâ”€â”€ LGE/
â”‚   â”‚   â”œâ”€â”€ T2w/
â”‚   â”‚   â””â”€â”€ label/
â”‚   â”‚         â”œâ”€â”€ case0001_gt.nii.gz
â”‚   â”‚         â”œâ”€â”€ ...
â”‚   â”‚         â””â”€â”€ case0380_gt.nii.gz   
â”‚   â”‚                              
â”‚   â””â”€â”€ Processed_data/   # preprocessed data for training/testing
â”‚       â”œâ”€â”€ bSSFP/
â”‚       â”‚     â”œâ”€â”€ train_npz
â”‚       â”‚     â”‚    â”œâ”€â”€ case0002_slice000.npz
â”‚       â”‚     â”‚    â”œâ”€â”€ case0002_slice001.npz
â”‚       â”‚     â”‚    â”œâ”€â”€ ...          
â”‚       â”‚     â”‚    â””â”€â”€ case0380_slice003.npz   
â”‚       â”‚     â””â”€â”€ test_vol_h5
â”‚       â”‚          â”œâ”€â”€ case0001.npy.h5
â”‚       â”‚          â”œâ”€â”€ case0006.npy.h5
â”‚       â”‚          â”œâ”€â”€ ...          
â”‚       â”‚          â””â”€â”€ case0376.npy.h5  
â”‚       â”œâ”€â”€ LGE/
â”‚       â””â”€â”€ T2w/
â”œâ”€â”€ preprocess_data.py                 # preprocessing script
â”œâ”€â”€ train.py                           # training script
â”œâ”€â”€ test.py                            # inference script
â”œâ”€â”€ environment.yaml                   # Reproducible conda environment definition
â””â”€â”€ README.md
```

### 3. Train/Test

- Run the train script on MyoPS380 dataset. The batch size can be reduced to 12 or 6 to save memory (please also decrease the base_lr linearly), and both can reach similar performance.

```bash
CUDA_VISIBLE_DEVICES= "0,1" python train.py --dataset Myops --vit_name R50-ViT-B_16
```

- Run the test script on MyoPS380 dataset.

```bash
python test.py --dataset Myops --vit_name R50-ViT-B_16
```

### 4. Dataset Description --- MyoPS380 dataset

**1. Background**

Assessing myocardial viability is critical for the diagnosis and management of patients with myocardial infarction (MI). Cardiac magnetic resonance (CMR) plays a central role in this process, offering detailed structural, functional, and tissue-characterization information. Three commonly used CMR modalities provide complementary perspectives:

- **bSSFP (balanced Steady-State Free Precession)** â€” captures cardiac motion and provides clear anatomical boundaries.  
- **LGE (Late Gadolinium Enhancement)** â€” visualizes myocardial infarction and fibrotic tissue.  
- **T2-weighted (T2w)** â€” highlights acute injury and myocardial edema.

Together, these modalities enable comprehensive evaluation of myocardial tissue, facilitating differentiation between normal myocardium, scar (infarction), and edema. However, manual annotation is labor-intensive, time-consuming, and subject to inter-/intra-observer variability, motivating the need for automated multi-modality myocardial pathology segmentation.

To support research in this direction, the **MyoPS380 dataset** provides multi-modality CMR data from **380 patients**, including bSSFP, LGE, and T2W modalities along with pixel-wise myocardial pathology annotations. The dataset serves as a high-quality benchmark for developing advanced algorithms that exploit multi-modality complementary information for reliable myocardial pathology classification and segmentation, ultimately supporting clinically applicable AI solutions.

---

**2. Data Source and Quality Control**

Prior to inclusion in the MyoPS380 dataset, all candidate cases underwent systematic image quality screening to ensure data reliability and usability. The screening process involved: excluding cases with significant motion artefacts, cardiac motion artefacts, or structural distortion due to respiratory inconsistency; and excluding cases with missing key modalities (e.g., incomplete LGE acquisition) or inadequate ventricular coverage. After screening, **380 multi-modality CMR studies** acquired at **Renji Hospital, Shanghai Jiao Tong University School of Medicine (2017â€“2023)** were retained. These encompassed three modalitiesâ€”bSSFP, LGE, and T2Wâ€”providing a comprehensive and high-quality imaging foundation for cardiomyopathy analysis.

---

**3. Dataset Structure**

The dataset follows a unified naming and directory convention to facilitate model training, reproducibility, and further extension. Each patient's multi-modality images are stored separately by modality, with labels matched by patient ID.

```bash
MyoPS380_dataset/
â”œâ”€â”€ Raw_data/
â”‚   â”œâ”€â”€ bSSFP/
â”‚   â”‚     â”œâ”€â”€ case0001.nii.gz
â”‚   â”‚     â”œâ”€â”€ ...
â”‚   â”‚     â””â”€â”€ case0380.nii.gz
â”‚   â”œâ”€â”€ LGE/
â”‚   â”‚     â”œâ”€â”€ case0001.nii.gz
â”‚   â”‚     â”œâ”€â”€ ...
â”‚   â”‚     â””â”€â”€ case0380.nii.gz
â”‚   â”œâ”€â”€ T2w/
â”‚   â”‚     â”œâ”€â”€ case0001.nii.gz
â”‚   â”‚     â”œâ”€â”€ ...
â”‚   â”‚     â””â”€â”€ case0380.nii.gz
â”‚   â””â”€â”€ label/
â”‚         â”œâ”€â”€ case0001_gt.nii.gz
â”‚         â”œâ”€â”€ ...
â”‚         â””â”€â”€ case0380_gt.nii.gz
```

- `caseXXXX.nii.gz`: the 3D CMR volume of a single modality.  
- `caseXXXX_gt.nii.gz`: merged myocardial pathology labels (normal myocardium, scar, edema).  

Annotations were performed by **three experienced radiologists** on modality-specific images and validated by a senior radiologist. All images and labels are stored in **NIfTI** format for convenient cross-platform use and deep learning integration.

---

**4. Preprocessing Pipeline**

To address inherent differences across multi-modality CMR (bSSFP, LGE, T2W)â€”including slice count, imaging geometry, and voxel resolutionâ€”we designed a structured preprocessing pipeline to ensure spatial consistency and improve model training stability. The detailed processing flowchart and particulars are as follows:

![processing flowchart](./processing.png)

***(1) Slice-Level Correspondence Construction***

Slice numbers differ across modalities, hindering accurate fusion. For each case:

- DICOM `ImagePositionPatient` was used to compute the 3D spatial coordinates of slices.
- The modality with the fewest slices was chosen as the reference.
- A nearest-neighbor matching strategy (Euclidean distance) established one-to-one slice correspondence.
- Unmatchable slices were automatically discarded.

This process ensures consistent slice counts and better multi-modal compatibility.

---

***(2) Spatial Normalization: Resampling and Center Cropping***

To mitigate scale inconsistencies:

- bSSFP (1.172Ã—1.172 mm), LGE (0.8929Ã—0.8929 mm), and T2W (0.8929Ã—0.8929 mm) images were **resampled to 1Ã—1 mm** in-plane resolution.
- Central cropping to **224Ã—224** ensured uniform input size and focus on the cardiac region.
- Pixel intensities were **linearly normalized to [0, 255]** to harmonize modality intensity ranges.

---

***(3) Slice-wise 2D Affine Registration Guided by Myocardial Masks***

Due to inter-modality differences influenced by respiration, cardiac motion, and acquisition parameters, significant spatial misalignment exists.

- A 2D affine transformation (rotation, scaling, shearing, translation) was estimated slice-by-slice.
- Myocardial segmentation masks served as structural priors for registration.
- The estimated transform was applied to both images and labels for high-accuracy alignment within the myocardial region.

---

***(4) Voxelmorph-Based Non-Rigid Deep Registration***

Affine alignment captures only linear transformations. To correct non-linear deformations across modalities:

- A 2D Voxelmorph model was applied to each slice.
- The model learns pixel-level deformation fields between fixed and moving modalities.
- Deformation fields were propagated to all modalities and labels.

This step substantially enhances geometric consistency in the myocardial region.

---

***(5) Final ROI Cropping and Data Packaging***

- Myocardial masks were used to perform ROI cropping, reducing background redundancy.
- Final images were standardized to **128Ã—128**.
- Aligned modality slices were stacked into 3D volumes (NIfTI) for training and evaluation.

This pipeline yields spatially coherent, scale-normalized, and structurally standardized multi-modality CMR data.

---

**5. Representative Examples**

The dataset covers a broad spectrum of myocardial pathology, ranging from mild infarction to extensive transmural MI accompanied by widespread edema.

Below are two groups of representative multi-modality slices with annotations:

![Representative Examples](./MyoPS380_dataset.png)

These examples highlight:1. modality-specific contrast characteristics. 2. inter-subject structural variability. 3. high consistency among expert annotations.
The visual diversity underscores the necessity of multi-modality fusion and supports the development of robust segmentation algorithms.

---

**5. Ethical Approval**

The MyoPS380 dataset was approved by the Ethics Committee of Renji Hospital, Shanghai Jiao Tong University School of Medicine **(Approval No. [2018]093)**  
and fully anonymized before data release to ensure patient privacy and compliance with ethical standards.

---

**6. Data Usage Guidelines**

The **MyoPS380 dataset** is currently undergoing peer review as part of an accompanying publication.  
Pending successful completion of the final compliance check, it is expected to be publicly released **before January 2026**.

You can download the dataset release agreement from ðŸ‘‰ [here](./MyoPS380_Dataset_Release_Agreement.docx).

Please ensure that a permanent or long-term responsible person (e.g., professor) completes the form with a **handwritten signature**.  
After signing, send the scanned electronic version to:**donggenf@whu.edu.cn**, **Subject:** *MyoPS380 Dataset Release Agreement*.
Please send the email from an **institutional email address** (e.g., xxx@xxx.edu.xx). Requests sent from free email providers (Outlook, QQ, Hotmail, etc.) will be politely declined.

After verifying your information, we will send you the dataset download link. We usually reply within a week. If you do not receive a responseâ€”possibly due to delivery issuesâ€”please modify the email content or title and try resending.

## Reference
* [Google ViT](https://github.com/google-research/vision_transformer)
* [ViT-pytorch](https://github.com/jeonsworld/ViT-pytorch)
* [TransUNet](https://github.com/Beckschen/TransUNet/tree/main)
* [Voxelmorph](https://github.com/voxelmorph/voxelmorph/tree/dev?tab=readme-ov-file)

<!-- ## Citations


```bibtex
@article{chen2021transunet,
  title={TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation},
  author={Chen, Jieneng and Lu, Yongyi and Yu, Qihang and Luo, Xiangde and Adeli, Ehsan and Wang, Yan and Lu, Le and Yuille, Alan L., and Zhou, Yuyin},
  journal={arXiv preprint arXiv:2102.04306},
  year={2021}
}
``` -->
